#!/usr/bin/env python3
"""
KnowFlow æ’ä»¶æµ‹è¯•è„šæœ¬
æµ‹è¯• batch_add_chunk æ’ä»¶åŠŸèƒ½
"""

import requests
import json
import time
from typing import List, Dict, Optional


class KnowFlowPluginTester:
    """KnowFlow æ’ä»¶æµ‹è¯•å™¨"""
    
    def __init__(self, base_url: str = "http://localhost", api_key: str = ""):
        """
        åˆå§‹åŒ–æµ‹è¯•å™¨
        
        Args:
            base_url: RAGFlow æœåŠ¡çš„åŸºç¡€URL
            api_key: APIå¯†é’¥
        """
        self.base_url = base_url.rstrip('/')
        self.api_key = api_key
        self.headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {api_key}' if api_key else ''
        }
    
    def test_plugin_batch_add_chunks(self, 
                                   dataset_id: str, 
                                   document_id: str, 
                                   chunks: List[Dict],
                                   batch_size: Optional[int] = None) -> Dict:
        """
        æµ‹è¯•æ’ä»¶ç‰ˆæœ¬çš„æ‰¹é‡æ·»åŠ  chunks
        
        Args:
            dataset_id: æ•°æ®é›†ID
            document_id: æ–‡æ¡£ID
            chunks: chunkæ•°æ®åˆ—è¡¨
            batch_size: æ‰¹é‡å¤„ç†å¤§å°
            
        Returns:
            APIå“åº”ç»“æœ
        """
        # æ–°çš„æ’ä»¶ API ç«¯ç‚¹ï¼ˆä½¿ç”¨æ­£ç¡®çš„è·¯å¾„ï¼‰
        url = f"{self.base_url}/api/v1/datasets/{dataset_id}/documents/{document_id}/chunks/batch"
        
        payload = {"chunks": chunks}
        if batch_size:
            payload["batch_size"] = batch_size
        
        print(f"ğŸ”Œ æµ‹è¯• KnowFlow æ’ä»¶ API: {url}")
        print(f"ğŸ“Š æ‰¹é‡å¤§å°: {len(chunks)} chunks")
        if batch_size:
            print(f"ğŸ”§ å¤„ç†åˆ†ç‰‡: {batch_size}")
        
        try:
            start_time = time.time()
            response = requests.post(url, headers=self.headers, json=payload, timeout=60)
            end_time = time.time()
            
            print(f"â±ï¸  è¯·æ±‚è€—æ—¶: {end_time - start_time:.2f} ç§’")
            print(f"ğŸ“¤ HTTPçŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                self._print_plugin_success_result(result)
                return result
            else:
                print(f"âŒ æ’ä»¶è¯·æ±‚å¤±è´¥:")
                print(f"   çŠ¶æ€ç : {response.status_code}")
                print(f"   å“åº”: {response.text}")
                return {"error": response.text}
                
        except requests.exceptions.RequestException as e:
            print(f"âŒ ç½‘ç»œè¯·æ±‚å¼‚å¸¸: {e}")
            return {"error": str(e)}
    
    def _print_plugin_success_result(self, result: Dict):
        """æ‰“å°æ’ä»¶æµ‹è¯•æˆåŠŸç»“æœ"""
        print("æ¥å£åŸå§‹è¿”å›ï¼š", result)
        data = result.get('data', {})
        if data is None:
            print("è­¦å‘Šï¼šæ¥å£ data å­—æ®µä¸º Noneï¼Œåç«¯æœªè¿”å›æœ‰æ•ˆæ•°æ®ï¼")
            data = {}
        
        print("âœ… KnowFlow æ’ä»¶æµ‹è¯•æˆåŠŸ!")
        print(f"   âœ… æˆåŠŸæ·»åŠ : {data.get('total_added', 0)} chunks")
        
        if data.get('total_failed', 0) > 0:
            print(f"   âŒ å¤±è´¥æ•°é‡: {data.get('total_failed', 0)} chunks")
        
        # å¤„ç†ç»Ÿè®¡ä¿¡æ¯
        stats = data.get('processing_stats', {})
        if stats:
            print("ğŸ“Š æ’ä»¶å¤„ç†ç»Ÿè®¡:")
            print(f"   ğŸ“¥ è¯·æ±‚æ€»æ•°: {stats.get('total_requested', 0)}")
            print(f"   ğŸ”„ åˆ†ç‰‡å¤§å°: {stats.get('batch_size_used', 0)}")
            print(f"   ğŸ“¦ å¤„ç†æ‰¹æ¬¡: {stats.get('batches_processed', 0)}")
            print(f"   ğŸ’° åµŒå…¥æˆæœ¬: {stats.get('embedding_cost', 0)}")
            
            errors = stats.get('processing_errors')
            if errors:
                print(f"   âš ï¸  å¤„ç†é”™è¯¯: {len(errors)} ä¸ª")
                for error in errors[:3]:
                    print(f"      - {error}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ’ä»¶ç‰¹æœ‰çš„å­—æ®µ
        chunks_result = data.get('chunks', [])
        if chunks_result:
            print(f"   ğŸ“„ è¿”å›chunks: {len(chunks_result)} ä¸ª")
    
    def create_test_chunks(self, count: int = 5, content_prefix: str = "KnowFlowæ’ä»¶æµ‹è¯•") -> List[Dict]:
        """
        åˆ›å»ºæµ‹è¯•ç”¨çš„ chunk æ•°æ®
        
        Args:
            count: åˆ›å»ºçš„chunkæ•°é‡
            content_prefix: å†…å®¹å‰ç¼€
            
        Returns:
            chunkæ•°æ®åˆ—è¡¨
        """
        chunks = []
        for i in range(count):
            chunk = {
                "content": f"{content_prefix} {i+1} - è¿™æ˜¯ä¸€ä¸ªç”¨äºæµ‹è¯•KnowFlowæ’ä»¶ç³»ç»Ÿçš„ç¤ºä¾‹æ–‡æœ¬å†…å®¹ã€‚éªŒè¯å¢é‡æ’ä»¶æ˜¯å¦æ­£å¸¸å·¥ä½œï¼Œè€Œä¸éœ€è¦æ›¿æ¢æ•´ä¸ªenhanced_doc.pyæ–‡ä»¶ã€‚",
                "important_keywords": [f"æ’ä»¶{i+1}", f"æµ‹è¯•{i+1}", "KnowFlow", "å¢é‡æŒ‚è½½"],
                "questions": [
                    f"ä»€ä¹ˆæ˜¯{content_prefix} {i+1}ï¼Ÿ",
                    f"KnowFlowæ’ä»¶ç³»ç»Ÿå¦‚ä½•å·¥ä½œï¼Ÿ"
                ]
            }
            chunks.append(chunk)
        return chunks
    
    def create_test_chunks_with_positions(self, count: int = 3, content_prefix: str = "ä½ç½®æ’ä»¶æµ‹è¯•") -> List[Dict]:
        """
        åˆ›å»ºåŒ…å«ä½ç½®ä¿¡æ¯çš„æµ‹è¯• chunk æ•°æ®
        
        Args:
            count: åˆ›å»ºçš„chunkæ•°é‡
            content_prefix: å†…å®¹å‰ç¼€
            
        Returns:
            åŒ…å«ä½ç½®ä¿¡æ¯çš„chunkæ•°æ®åˆ—è¡¨
        """
        chunks = []
        for i in range(count):
            chunk = {
                "content": f"{content_prefix} {i+1} - è¿™æ˜¯ä¸€ä¸ªåŒ…å«ä½ç½®ä¿¡æ¯çš„KnowFlowæ’ä»¶æµ‹è¯•å†…å®¹ã€‚éªŒè¯ä½ç½®ä¿¡æ¯å¤„ç†æ˜¯å¦æ­£ç¡®ã€‚",
                "important_keywords": [f"ä½ç½®{i+1}", f"æ’ä»¶{i+1}", "KnowFlow", "ä½ç½®æµ‹è¯•"],
                "questions": [
                    f"ä»€ä¹ˆæ˜¯{content_prefix} {i+1}çš„ä½ç½®ï¼Ÿ",
                    f"æ’ä»¶å¦‚ä½•å¤„ç†ä½ç½®ä¿¡æ¯ï¼Ÿ"
                ],
                "positions": [
                    [i+1, 100 + i*50, 500 + i*50, 200 + i*30, 250 + i*30],
                    [i+1, 100 + i*50, 500 + i*50, 260 + i*30, 310 + i*30]
                ]
            }
            chunks.append(chunk)
        return chunks
    
    def run_plugin_test_suite(self, dataset_id: str, document_id: str):
        """
        è¿è¡Œå®Œæ•´çš„æ’ä»¶æµ‹è¯•å¥—ä»¶
        
        Args:
            dataset_id: æ•°æ®é›†ID
            document_id: æ–‡æ¡£ID
        """
        print("ğŸ§ª KnowFlow æ’ä»¶ç³»ç»Ÿæµ‹è¯•å¥—ä»¶")
        print("=" * 60)
        
        # æµ‹è¯•1: åŸºç¡€æ’ä»¶åŠŸèƒ½æµ‹è¯•
        print("\nğŸ“‹ æµ‹è¯•1: åŸºç¡€æ’ä»¶åŠŸèƒ½ (5 chunks)")
        print("-" * 40)
        basic_chunks = self.create_test_chunks(5, "åŸºç¡€æ’ä»¶æµ‹è¯•")
        result1 = self.test_plugin_batch_add_chunks(dataset_id, document_id, basic_chunks, batch_size=2)
        
        time.sleep(2)
        
        # æµ‹è¯•2: ä½ç½®ä¿¡æ¯æ’ä»¶æµ‹è¯•
        print("\nğŸ“‹ æµ‹è¯•2: ä½ç½®ä¿¡æ¯æ’ä»¶æµ‹è¯• (3 chunks)")
        print("-" * 40)
        position_chunks = self.create_test_chunks_with_positions(3, "ä½ç½®æ’ä»¶æµ‹è¯•")
        result2 = self.test_plugin_batch_add_chunks(dataset_id, document_id, position_chunks, batch_size=1)
        
        time.sleep(2)
        
        # æµ‹è¯•3: å¤§æ‰¹é‡æ’ä»¶æµ‹è¯•
        print("\nğŸ“‹ æµ‹è¯•3: å¤§æ‰¹é‡æ’ä»¶æµ‹è¯• (20 chunks)")
        print("-" * 40)
        large_chunks = self.create_test_chunks(20, "å¤§æ‰¹é‡æ’ä»¶æµ‹è¯•")
        result3 = self.test_plugin_batch_add_chunks(dataset_id, document_id, large_chunks, batch_size=5)
        
        # æµ‹è¯•æ€»ç»“
        print("\nğŸ“Š æ’ä»¶æµ‹è¯•æ€»ç»“")
        print("=" * 60)
        
        tests = [
            ("åŸºç¡€æ’ä»¶æµ‹è¯•", result1),
            ("ä½ç½®ä¿¡æ¯æ’ä»¶æµ‹è¯•", result2),
            ("å¤§æ‰¹é‡æ’ä»¶æµ‹è¯•", result3)
        ]
        
        total_added = 0
        total_failed = 0
        
        for test_name, result in tests:
            if 'error' not in result:
                data = result.get('data', {})
                added = data.get('total_added', 0)
                failed = data.get('total_failed', 0)
                total_added += added
                total_failed += failed
                print(f"âœ… {test_name}: +{added} chunks (å¤±è´¥: {failed})")
            else:
                print(f"âŒ {test_name}: æµ‹è¯•å¤±è´¥")
        
        print(f"\nğŸ¯ æ’ä»¶ç³»ç»Ÿæ€»è®¡:")
        print(f"   âœ… æˆåŠŸæ·»åŠ : {total_added} chunks")
        print(f"   âŒ å¤±è´¥æ•°é‡: {total_failed} chunks")
        print(f"   ğŸ“ˆ æˆåŠŸç‡: {(total_added/(total_added+total_failed)*100):.1f}%" if (total_added + total_failed) > 0 else "N/A")
        
        if total_added > 0:
            print(f"\nğŸ‰ KnowFlow æ’ä»¶ç³»ç»Ÿæµ‹è¯•é€šè¿‡!")
            print(f"   ğŸ”Œ æ’ä»¶æ­£å¸¸å·¥ä½œï¼Œæ— éœ€ç»´æŠ¤æ•´ä¸ª enhanced_doc.py")
            print(f"   ğŸ“¦ å¢é‡æŒ‚è½½æ–¹å¼éªŒè¯æˆåŠŸ")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ KnowFlow æ’ä»¶ç³»ç»Ÿæµ‹è¯•å·¥å…·")
    print("=" * 60)
    
    # é…ç½®å‚æ•°
    BASE_URL = "http://localhost:9380"
    API_KEY = "ragflow-EzZDcyMGM0NWY5ZDExZjBhODQ2NDY0N2"
    
    # æµ‹è¯•å‚æ•°
    DATASET_ID = "abea3a645f9c11f092b39a1d66cae0eb"
    DOCUMENT_ID = "dececf525ff711f09df566fc51ac58de"
    
    # æ£€æŸ¥å‚æ•°
    if DATASET_ID == "your_dataset_id_here" or DOCUMENT_ID == "your_document_id_here":
        print("âš ï¸  è¯·å…ˆé…ç½®æµ‹è¯•å‚æ•°!")
        print("è¯·åœ¨è„šæœ¬ä¸­ä¿®æ”¹ä»¥ä¸‹å˜é‡:")
        print(f"   DATASET_ID = '{DATASET_ID}'")
        print(f"   DOCUMENT_ID = '{DOCUMENT_ID}'")
        return
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = KnowFlowPluginTester(BASE_URL, API_KEY)
    
    print("\nğŸ”Œ å¼€å§‹æµ‹è¯• KnowFlow æ’ä»¶ç³»ç»Ÿ...")
    print("æ³¨æ„: ç¡®ä¿å·²æ­£ç¡®é…ç½® Docker æŒ‚è½½:")
    print("   ./knowflow_plugins:/ragflow/api/apps/knowflow_plugins:ro")
    print("")
    
    # è¿è¡Œæ’ä»¶æµ‹è¯•å¥—ä»¶
    tester.run_plugin_test_suite(DATASET_ID, DOCUMENT_ID)


if __name__ == "__main__":
    main()